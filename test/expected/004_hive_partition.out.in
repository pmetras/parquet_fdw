-- Hive partitioning tests
SET datestyle = 'ISO';
SET client_min_messages = WARNING;
SET log_statement TO 'none';
-- Clean up any leftover objects from previous test runs
-- Note: test 003 leaves example_parent tables owned by regress_parquet_fdw
DROP TABLE IF EXISTS example_parent1 CASCADE;
DROP TABLE IF EXISTS example_parent2 CASCADE;
DROP EXTENSION IF EXISTS parquet_fdw CASCADE;
DROP ROLE IF EXISTS regress_parquet_fdw;
-- Create fresh objects
CREATE EXTENSION parquet_fdw;
CREATE ROLE regress_parquet_fdw LOGIN SUPERUSER;
CREATE SERVER parquet_srv FOREIGN DATA WRAPPER parquet_fdw;
CREATE USER MAPPING FOR regress_parquet_fdw SERVER parquet_srv;
SET ROLE regress_parquet_fdw;
-- Test 1: Basic Hive partitioning with virtual columns
-- The directory structure is: hive/basic/year=YYYY/month=M/data.parquet
-- Parquet files contain: id, amount, name
-- year and month are virtual columns extracted from path
CREATE FOREIGN TABLE hive_basic (
    id BIGINT,
    amount FLOAT8,
    name TEXT,
    year INT,      -- virtual column from path
    month INT      -- virtual column from path
)
SERVER parquet_srv
OPTIONS (
    filename '@abs_srcdir@/data/hive/basic/year=2023/month=1/data.parquet @abs_srcdir@/data/hive/basic/year=2023/month=2/data.parquet @abs_srcdir@/data/hive/basic/year=2024/month=1/data.parquet @abs_srcdir@/data/hive/basic/year=2024/month=2/data.parquet',
    hive_partitioning 'true'
);
-- Verify all data is read with virtual columns
SELECT * FROM hive_basic ORDER BY id;
 id | amount |  name   | year | month 
----+--------+---------+------+-------
  1 |    100 | Alice   | 2023 |     1
  2 |    200 | Bob     | 2023 |     1
  3 |    150 | Charlie | 2023 |     2
  4 |    250 | Diana   | 2023 |     2
  5 |    175 | Eve     | 2024 |     1
  6 |    225 | Frank   | 2024 |     1
  7 |    125 | Grace   | 2024 |     2
  8 |    275 | Henry   | 2024 |     2
(8 rows)

-- Test partition pruning: only scan year=2023 (4 rows from 2 files)
SELECT * FROM hive_basic WHERE year = 2023 ORDER BY id;
 id | amount |  name   | year | month 
----+--------+---------+------+-------
  1 |    100 | Alice   | 2023 |     1
  2 |    200 | Bob     | 2023 |     1
  3 |    150 | Charlie | 2023 |     2
  4 |    250 | Diana   | 2023 |     2
(4 rows)

-- Test partition pruning: only scan month=1 (4 rows from 2 files)
SELECT * FROM hive_basic WHERE month = 1 ORDER BY id;
 id | amount | name  | year | month 
----+--------+-------+------+-------
  1 |    100 | Alice | 2023 |     1
  2 |    200 | Bob   | 2023 |     1
  5 |    175 | Eve   | 2024 |     1
  6 |    225 | Frank | 2024 |     1
(4 rows)

-- Test partition pruning: year=2024 AND month=2 (2 rows from 1 file)
SELECT * FROM hive_basic WHERE year = 2024 AND month = 2 ORDER BY id;
 id | amount | name  | year | month 
----+--------+-------+------+-------
  7 |    125 | Grace | 2024 |     2
  8 |    275 | Henry | 2024 |     2
(2 rows)

-- EXPLAIN should show partition info
EXPLAIN (COSTS OFF) SELECT * FROM hive_basic WHERE year = 2023;
         QUERY PLAN         
----------------------------
 Foreign Scan on hive_basic
   Filter: (year = 2023)
   Reader: Multifile
   Row groups: 
     data.parquet: 1
     data.parquet: 1
(6 rows)

-- Test 2: Text partition values
CREATE FOREIGN TABLE hive_region (
    id BIGINT,
    sales FLOAT8,
    region TEXT    -- virtual column from path
)
SERVER parquet_srv
OPTIONS (
    filename '@abs_srcdir@/data/hive/region/region=US/data.parquet @abs_srcdir@/data/hive/region/region=EU/data.parquet',
    hive_partitioning 'true'
);
-- Verify all data with region partition column
SELECT * FROM hive_region ORDER BY id;
 id | sales | region 
----+-------+--------
  1 |  1000 | US
  2 |  1500 | US
  3 |  2000 | EU
  4 |  2500 | EU
(4 rows)

-- Test partition pruning with text value (2 rows from 1 file)
SELECT * FROM hive_region WHERE region = 'US' ORDER BY id;
 id | sales | region 
----+-------+--------
  1 |  1000 | US
  2 |  1500 | US
(2 rows)

-- Test 3: Mixed queries with partition and non-partition filters
SELECT * FROM hive_basic WHERE year = 2023 AND amount > 150 ORDER BY id;
 id | amount | name  | year | month 
----+--------+-------+------+-------
  2 |    200 | Bob   | 2023 |     1
  4 |    250 | Diana | 2023 |     2
(2 rows)

SELECT * FROM hive_basic WHERE year = 2024 AND name LIKE 'E%' ORDER BY id;
 id | amount | name | year | month 
----+--------+------+------+-------
  5 |    175 | Eve  | 2024 |     1
(1 row)

-- Test 4: Aggregates with partition values
SELECT year, month, COUNT(*), SUM(amount)
FROM hive_basic
GROUP BY year, month
ORDER BY year, month;
 year | month | count | sum 
------+-------+-------+-----
 2023 |     1 |     2 | 300
 2023 |     2 |     2 | 400
 2024 |     1 |     2 | 400
 2024 |     2 |     2 | 400
(4 rows)

SELECT year, COUNT(*) as cnt
FROM hive_basic
WHERE year = 2023
GROUP BY year;
 year | cnt 
------+-----
 2023 |   4
(1 row)

-- Test 5: IMPORT FOREIGN SCHEMA with tables_map and tables_partition_map
-- Two tables with different date columns but same partition structure
-- table1 has event_date, table2 has data_date
-- Note: glob() doesn't support ** (globstar), so we use year=*/month=*/*.parquet
IMPORT FOREIGN SCHEMA "@abs_srcdir@/data/hive/import_test"
FROM SERVER parquet_srv
INTO public
OPTIONS (
    hive_partitioning 'true',
    tables_map 'table1=@abs_srcdir@/data/hive/import_test/table1/year=*/month=*/*.parquet table2=@abs_srcdir@/data/hive/import_test/table2/year=*/month=*/*.parquet',
    tables_partition_map 'table1:year={YEAR(event_date)},month={MONTH(event_date)} table2:year={YEAR(data_date)},month={MONTH(data_date)}'
);
-- Verify table1 was created and data is accessible
SELECT * FROM table1 ORDER BY id;
 id | event_date | value 
----+------------+-------
  1 | 2023-01-15 |   100
  2 | 2023-01-20 |   200
  3 | 2023-06-10 |   150
  4 | 2023-06-25 |   250
  5 | 2024-03-05 |   175
  6 | 2024-03-28 |   225
(6 rows)

-- Verify table2 was created and data is accessible
SELECT * FROM table2 ORDER BY id;
 id  | data_date  | amount 
-----+------------+--------
 101 | 2023-02-10 |   1000
 102 | 2023-02-28 |   2000
 103 | 2023-08-15 |   1500
 104 | 2023-08-30 |   2500
 105 | 2024-05-01 |   1750
 106 | 2024-05-20 |   2250
(6 rows)

-- Test partition pruning on table1 using event_date
-- Should only scan year=2023 partitions
SELECT id, event_date, value FROM table1 WHERE event_date >= '2023-01-01' AND event_date < '2024-01-01' ORDER BY id;
 id | event_date | value 
----+------------+-------
  1 | 2023-01-15 |   100
  2 | 2023-01-20 |   200
  3 | 2023-06-10 |   150
  4 | 2023-06-25 |   250
(4 rows)

-- Test partition pruning on table2 using data_date
-- Should only scan year=2024 partition
SELECT id, data_date, amount FROM table2 WHERE data_date >= '2024-01-01' ORDER BY id;
 id  | data_date  | amount 
-----+------------+--------
 105 | 2024-05-01 |   1750
 106 | 2024-05-20 |   2250
(2 rows)

-- Verify EXPLAIN shows the tables
EXPLAIN (COSTS OFF) SELECT * FROM table1 WHERE event_date = '2023-01-15';
                 QUERY PLAN                  
---------------------------------------------
 Foreign Scan on table1
   Filter: (event_date = '2023-01-15'::date)
   Reader: Single File
   Row groups: 1
(4 rows)

EXPLAIN (COSTS OFF) SELECT * FROM table2 WHERE data_date = '2024-05-01';
                 QUERY PLAN                 
--------------------------------------------
 Foreign Scan on table2
   Filter: (data_date = '2024-05-01'::date)
   Reader: Single File
   Row groups: 1
(4 rows)

-- Clean up imported tables
DROP FOREIGN TABLE table1;
DROP FOREIGN TABLE table2;
-- =============================================================================
-- Edge Case Tests
-- =============================================================================
-- Test 6: URL-encoded partition values
-- The partition path contains URL-encoded characters: region=North%20America
-- The FDW should decode %20 to space when returning partition values
CREATE FOREIGN TABLE hive_url_encoded (
    id BIGINT,
    sales FLOAT8,
    region TEXT    -- virtual column, URL-decoded from path
)
SERVER parquet_srv
OPTIONS (
    filename '@abs_srcdir@/data/hive/url_encoded/region=North%20America/data.parquet',
    hive_partitioning 'true'
);
-- Verify the region is correctly decoded to "North America"
SELECT * FROM hive_url_encoded ORDER BY id;
 id | sales |    region     
----+-------+---------------
  1 |  1000 | North America
  2 |  2000 | North America
  3 |  3000 | North America
(3 rows)

-- Verify filter works with decoded value
SELECT * FROM hive_url_encoded WHERE region = 'North America' ORDER BY id;
 id | sales |    region     
----+-------+---------------
  1 |  1000 | North America
  2 |  2000 | North America
  3 |  3000 | North America
(3 rows)

DROP FOREIGN TABLE hive_url_encoded;
-- Test 7: Three-level partition (year/month/day)
-- Tests deep nesting: year=2025/month=01/day=15
CREATE FOREIGN TABLE hive_three_level (
    id BIGINT,
    value FLOAT8,
    year INT,
    month INT,
    day INT
)
SERVER parquet_srv
OPTIONS (
    filename '@abs_srcdir@/data/hive/three_level/year=2025/month=01/day=15/data.parquet @abs_srcdir@/data/hive/three_level/year=2025/month=01/day=20/data.parquet @abs_srcdir@/data/hive/three_level/year=2025/month=02/day=10/data.parquet',
    hive_partitioning 'true'
);
-- Verify all data with three-level partitions
SELECT * FROM hive_three_level ORDER BY id;
 id | value | year | month | day 
----+-------+------+-------+-----
  1 |   100 | 2025 |     1 |  15
  2 |   200 | 2025 |     1 |  15
  3 |   150 | 2025 |     1 |  20
  4 |   250 | 2025 |     1 |  20
  5 |   175 | 2025 |     2 |  10
  6 |   225 | 2025 |     2 |  10
(6 rows)

-- Test pruning at each level
SELECT * FROM hive_three_level WHERE year = 2025 AND month = 1 ORDER BY id;
 id | value | year | month | day 
----+-------+------+-------+-----
  1 |   100 | 2025 |     1 |  15
  2 |   200 | 2025 |     1 |  15
  3 |   150 | 2025 |     1 |  20
  4 |   250 | 2025 |     1 |  20
(4 rows)

SELECT * FROM hive_three_level WHERE year = 2025 AND month = 1 AND day = 15 ORDER BY id;
 id | value | year | month | day 
----+-------+------+-------+-----
  1 |   100 | 2025 |     1 |  15
  2 |   200 | 2025 |     1 |  15
(2 rows)

SELECT * FROM hive_three_level WHERE month = 2 ORDER BY id;
 id | value | year | month | day 
----+-------+------+-------+-----
  5 |   175 | 2025 |     2 |  10
  6 |   225 | 2025 |     2 |  10
(2 rows)

DROP FOREIGN TABLE hive_three_level;
-- Test 8: Column conflict - column exists in both file and partition path
-- The partition path has year=2099, but the Parquet file contains a 'year' column
-- with different values (2025, 2026, 2027). File data takes precedence for column values.
-- NOTE: Partition pruning uses PATH values, so filtering on year will use 2099 for pruning.
CREATE FOREIGN TABLE hive_conflict (
    id BIGINT,
    year INT,     -- This column is in BOTH the Parquet file AND partition path
    value FLOAT8
)
SERVER parquet_srv
OPTIONS (
    filename '@abs_srcdir@/data/hive/conflict/year=2099/data.parquet',
    hive_partitioning 'true'
);
-- Year column values come from the Parquet file (2025, 2026, 2027), NOT from path (2099)
SELECT * FROM hive_conflict ORDER BY id;
 id | year | value 
----+------+-------
  1 | 2025 |   100
  2 | 2026 |   200
  3 | 2027 |   300
(3 rows)

-- Filter on year=2025 returns 0 rows because partition pruning uses path year=2099
-- This is expected: pruning happens before file reading
SELECT * FROM hive_conflict WHERE year = 2025 ORDER BY id;
 id | year | value 
----+------+-------
(0 rows)

DROP FOREIGN TABLE hive_conflict;
-- Test 9: Range spanning queries with partition_map
-- Tests that BETWEEN queries spanning partition boundaries include all needed partitions
CREATE FOREIGN TABLE hive_range_test (
    id BIGINT,
    event_date DATE,
    value FLOAT8,
    year INT,
    month INT
)
SERVER parquet_srv
OPTIONS (
    filename '@abs_srcdir@/data/hive/range_test/year=2025/month=01/data.parquet @abs_srcdir@/data/hive/range_test/year=2025/month=02/data.parquet @abs_srcdir@/data/hive/range_test/year=2025/month=03/data.parquet',
    hive_partitioning 'true',
    partition_map 'year={YEAR(event_date)},month={MONTH(event_date)}'
);
-- Verify all data
SELECT * FROM hive_range_test ORDER BY id;
 id | event_date | value | year | month 
----+------------+-------+------+-------
  1 | 2025-01-10 |   100 | 2025 |     1
  2 | 2025-01-20 |   200 | 2025 |     1
  3 | 2025-01-31 |   300 | 2025 |     1
  4 | 2025-02-01 |   400 | 2025 |     2
  5 | 2025-02-15 |   500 | 2025 |     2
  6 | 2025-02-28 |   600 | 2025 |     2
  7 | 2025-03-01 |   700 | 2025 |     3
  8 | 2025-03-15 |   800 | 2025 |     3
(8 rows)

-- Range query spanning January and February (should include both partitions)
SELECT * FROM hive_range_test WHERE event_date BETWEEN '2025-01-15' AND '2025-02-15' ORDER BY id;
 id | event_date | value | year | month 
----+------------+-------+------+-------
  2 | 2025-01-20 |   200 | 2025 |     1
  3 | 2025-01-31 |   300 | 2025 |     1
  4 | 2025-02-01 |   400 | 2025 |     2
  5 | 2025-02-15 |   500 | 2025 |     2
(4 rows)

-- EXPLAIN should show both month=01 and month=02 files are scanned
EXPLAIN (COSTS OFF) SELECT * FROM hive_range_test WHERE event_date BETWEEN '2025-01-15' AND '2025-02-15';
                                      QUERY PLAN                                       
---------------------------------------------------------------------------------------
 Foreign Scan on hive_range_test
   Filter: ((event_date >= '2025-01-15'::date) AND (event_date <= '2025-02-15'::date))
   Reader: Multifile
   Row groups: 
     data.parquet: 1
     data.parquet: 1
(6 rows)

-- Single month query (should prune to one partition)
SELECT * FROM hive_range_test WHERE event_date >= '2025-03-01' ORDER BY id;
 id | event_date | value | year | month 
----+------------+-------+------+-------
  7 | 2025-03-01 |   700 | 2025 |     3
  8 | 2025-03-15 |   800 | 2025 |     3
(2 rows)

DROP FOREIGN TABLE hive_range_test;
-- Clean up
DROP FOREIGN TABLE hive_basic;
DROP FOREIGN TABLE hive_region;
DROP USER MAPPING FOR regress_parquet_fdw SERVER parquet_srv;
DROP SERVER parquet_srv CASCADE;
RESET ROLE;
DROP ROLE regress_parquet_fdw;
DROP EXTENSION parquet_fdw CASCADE;
